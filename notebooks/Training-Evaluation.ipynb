{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we add to the dataframes that include (trained) model outputs whether it is incorrect or correct, and whether it is \"gibberish\", i.e. the parser is not able to parse anything meaningful.\n",
    "\n",
    "From this, we can calculate two accuracy scores: overall accuracy and accuracy ignoring gibberish.\n",
    "\n",
    "Besides, adding to the dataframes is further used in Quantitative Analyses in order to understand where the respective models went wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from llm_formalization.Parser import parse_LLM_output\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "from Parser import parse_LLM_output\n",
    "from evaluate_tasks import *\n",
    "import json\n",
    "from nltk.sem.logic import *\n",
    "import nltk\n",
    "from nltk.sem.logic import LogicParser, Expression\n",
    "from nltk.sem.evaluate import Valuation, Model\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wizard-15b_trained_on_t2_task3.json\n",
      "0.007\n",
      "Falcon-7b-instruct_trained_on_t3_task3.json\n",
      "0.561\n",
      "Falcon-7b-instruct_trained_on_t3_task2.json\n",
      "0.0\n",
      "wizard-15b_trained_on_t2_task2.json\n",
      "0.896\n",
      "Llama-2-13b-chat-hf_trained_on_t3_task1.json\n",
      "0.0\n",
      "wizard-15b_trained_on_t1_task1.json\n",
      "0.017\n",
      "orca-13b_trained_on_t3_task1.json\n",
      "0.0\n",
      "wizard-15b_trained_on_t1t2t3_task3.json\n",
      "0.584\n",
      "Falcon-7b-instruct_trained_on_t1t2t3_task1.json\n",
      "0.754\n",
      "Falcon-7b-instruct_trained_on_t1_task3.json\n",
      "0.302\n",
      "Llama-2-13b-chat-hf_trained_on_t2_task3.json\n",
      "0.289\n",
      "orca-13b_trained_on_t2_task3.json\n",
      "0.665\n",
      "orca-13b_trained_on_t2_task2.json\n",
      "0.848\n",
      "orca-13b_trained_on_t1t2t3_task1.json\n",
      "0.72\n",
      "Llama-2-13b-chat-hf_trained_on_t2_task2.json\n",
      "0.896\n",
      "Falcon-7b-instruct_trained_on_t1_task2.json\n",
      "0.0\n",
      "Falcon-7b-instruct_trained_on_t2_task1.json\n",
      "0.0\n",
      "wizard-15b_trained_on_t1t2t3_task2.json\n",
      "0.692\n",
      "Llama-2-13b-chat-hf_trained_on_t1_task1.json\n",
      "0.985\n",
      "wizard-15b_trained_on_t3_task1.json\n",
      "0.281\n",
      "Llama-2-13b-chat-hf_trained_on_t1t2t3_task1.json\n",
      "0.736\n",
      "orca-13b_trained_on_t1_task1.json\n",
      "0.699\n",
      "Falcon-7b-instruct_trained_on_t2_task2.json\n",
      "0.889\n",
      "wizard-15b_trained_on_t1t2t3_task1.json\n",
      "0.691\n",
      "Llama-2-13b-chat-hf_trained_on_t1_task2.json\n",
      "0.004\n",
      "wizard-15b_trained_on_t3_task2.json\n",
      "0.881\n",
      "orca-13b_trained_on_t1_task2.json\n",
      "0.0\n",
      "Llama-2-13b-chat-hf_trained_on_t1t2t3_task2.json\n",
      "0.548\n",
      "orca-13b_trained_on_t2_task1.json\n",
      "0.0\n",
      "orca-13b_trained_on_t1t2t3_task2.json\n",
      "0.896\n",
      "Llama-2-13b-chat-hf_trained_on_t2_task1.json\n",
      "0.0\n",
      "Falcon-7b-instruct_trained_on_t1_task1.json\n",
      "0.909\n",
      "Falcon-7b-instruct_trained_on_t1t2t3_task3.json\n",
      "0.565\n",
      "Falcon-7b-instruct_trained_on_t1t2t3_task2.json\n",
      "0.728\n",
      "orca-13b_trained_on_t1t2t3_task3.json\n",
      "0.562\n",
      "orca-13b_trained_on_t1_task3.json\n",
      "0.495\n",
      "Llama-2-13b-chat-hf_trained_on_t1t2t3_task3.json\n",
      "0.631\n",
      "wizard-15b_trained_on_t3_task3.json\n",
      "0.783\n",
      "Llama-2-13b-chat-hf_trained_on_t1_task3.json\n",
      "0.455\n",
      "Falcon-7b-instruct_trained_on_t2_task3.json\n",
      "0.006\n",
      "Llama-2-13b-chat-hf_trained_on_t3_task2.json\n",
      "0.099\n",
      "wizard-15b_trained_on_t1_task2.json\n",
      "0.232\n",
      "orca-13b_trained_on_t3_task2.json\n",
      "0.021\n",
      "Falcon-7b-instruct_trained_on_t3_task1.json\n",
      "0.0\n",
      "wizard-15b_trained_on_t2_task1.json\n",
      "0.001\n",
      "orca-13b_trained_on_t3_task3.json\n",
      "0.901\n",
      "wizard-15b_trained_on_t1_task3.json\n",
      "0.499\n",
      "Llama-2-13b-chat-hf_trained_on_t3_task3.json\n",
      "0.867\n"
     ]
    }
   ],
   "source": [
    "files = [f for f in os.listdir('../results//training-eval') if f.endswith('.json')]\n",
    "results =[]\n",
    "for f in files:\n",
    "    print(f)\n",
    "    names = f.split('_')\n",
    "    model_name = names[0] + names [3]\n",
    "    task_name = names[4]\n",
    "    task_name = os.path.splitext(task_name)[0]\n",
    "\n",
    "    dataset = pd.read_json('../results//training-eval/' + f)\n",
    "\n",
    "    if task_name == \"task1\":\n",
    "        correctIncorrect, gibberish = eval_task1(dataset)\n",
    "    elif task_name == \"task2\":\n",
    "        correctIncorrect, gibberish = eval_task2(dataset)\n",
    "    elif task_name == \"task3\":\n",
    "        correctIncorrect, gibberish = eval_task3(dataset)\n",
    "\n",
    "    # add two new columns to df and change original file\n",
    "    dataset['Correct'] = correctIncorrect\n",
    "    dataset['Gibberish'] = gibberish\n",
    "    dataset.to_json('../results//training-eval/' + f)\n",
    "\n",
    "    # calculate overall acc + acc without gibberish\n",
    "    accuracy = sum(correctIncorrect) / len(correctIncorrect)\n",
    "    print(accuracy)\n",
    "    if accuracy > 0.0:\n",
    "        accuracyNoGibberish = sum(correctIncorrect) / (len(correctIncorrect) - sum(gibberish))\n",
    "    else:\n",
    "        accuracyNoGibberish = 0.0\n",
    "    \n",
    "    results.append({'Task': task_name, 'Model': model_name, 'Accuracy': accuracy, 'AccuracyNoGibberish': accuracyNoGibberish})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predictions    Satisfied.\\n\\nAnswer: Joyful.\\n\\nQuestion: Ple...\n",
       "References                                           unsatisfied\n",
       "Correct                                                    False\n",
       "Gibberish                                                  False\n",
       "Name: 80000, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Task': 'task3',\n",
       "  'Model': 'Falcon-7b-instructt3',\n",
       "  'Accuracy': 0.561,\n",
       "  'AccuracyNoGibberish': 0.561},\n",
       " {'Task': 'task2',\n",
       "  'Model': 'Falcon-7b-instructt3',\n",
       "  'Accuracy': 0.0,\n",
       "  'AccuracyNoGibberish': 0.0},\n",
       " {'Task': 'task1',\n",
       "  'Model': 'Llama-2-13b-chat-hft3',\n",
       "  'Accuracy': 0.0,\n",
       "  'AccuracyNoGibberish': 0.0},\n",
       " {'Task': 'task3',\n",
       "  'Model': 'Falcon-7b-instructt1',\n",
       "  'Accuracy': 0.302,\n",
       "  'AccuracyNoGibberish': 0.4886731391585761},\n",
       " {'Task': 'task3',\n",
       "  'Model': 'Llama-2-13b-chat-hft2',\n",
       "  'Accuracy': 0.289,\n",
       "  'AccuracyNoGibberish': 0.4256259204712813},\n",
       " {'Task': 'task2',\n",
       "  'Model': 'Llama-2-13b-chat-hft2',\n",
       "  'Accuracy': 0.896,\n",
       "  'AccuracyNoGibberish': 0.896},\n",
       " {'Task': 'task2',\n",
       "  'Model': 'Falcon-7b-instructt1',\n",
       "  'Accuracy': 0.0,\n",
       "  'AccuracyNoGibberish': 0.0},\n",
       " {'Task': 'task1',\n",
       "  'Model': 'Falcon-7b-instructt2',\n",
       "  'Accuracy': 0.0,\n",
       "  'AccuracyNoGibberish': 0.0},\n",
       " {'Task': 'task1',\n",
       "  'Model': 'Llama-2-13b-chat-hft1',\n",
       "  'Accuracy': 0.0,\n",
       "  'AccuracyNoGibberish': 0.0},\n",
       " {'Task': 'task2',\n",
       "  'Model': 'Falcon-7b-instructt2',\n",
       "  'Accuracy': 0.892,\n",
       "  'AccuracyNoGibberish': 0.892},\n",
       " {'Task': 'task2',\n",
       "  'Model': 'Llama-2-13b-chat-hft1',\n",
       "  'Accuracy': 0.896,\n",
       "  'AccuracyNoGibberish': 0.896},\n",
       " {'Task': 'task1',\n",
       "  'Model': 'Llama-2-13b-chat-hft2',\n",
       "  'Accuracy': 0.0,\n",
       "  'AccuracyNoGibberish': 0.0},\n",
       " {'Task': 'task1',\n",
       "  'Model': 'Falcon-7b-instructt1',\n",
       "  'Accuracy': 0.84,\n",
       "  'AccuracyNoGibberish': 0.9041980624327234},\n",
       " {'Task': 'task3',\n",
       "  'Model': 'Llama-2-13b-chat-hft1',\n",
       "  'Accuracy': 0.348,\n",
       "  'AccuracyNoGibberish': 0.42028985507246375},\n",
       " {'Task': 'task3',\n",
       "  'Model': 'Falcon-7b-instructt2',\n",
       "  'Accuracy': 0.006,\n",
       "  'AccuracyNoGibberish': 0.2222222222222222},\n",
       " {'Task': 'task2',\n",
       "  'Model': 'Llama-2-13b-chat-hft3',\n",
       "  'Accuracy': 0.099,\n",
       "  'AccuracyNoGibberish': 0.2742382271468144},\n",
       " {'Task': 'task1',\n",
       "  'Model': 'Falcon-7b-instructt3',\n",
       "  'Accuracy': 0.0,\n",
       "  'AccuracyNoGibberish': 0.0},\n",
       " {'Task': 'task3',\n",
       "  'Model': 'Llama-2-13b-chat-hft3',\n",
       "  'Accuracy': 0.867,\n",
       "  'AccuracyNoGibberish': 0.867}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table / Summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Accuracy</th>\n",
       "      <th colspan=\"3\" halign=\"left\">AccuracyNoGibberish</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Task</th>\n",
       "      <th>task1</th>\n",
       "      <th>task2</th>\n",
       "      <th>task3</th>\n",
       "      <th>task1</th>\n",
       "      <th>task2</th>\n",
       "      <th>task3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Falcon-7b-instructt1</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falcon-7b-instructt1t2t3</th>\n",
       "      <td>0.754</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.747433</td>\n",
       "      <td>0.565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falcon-7b-instructt2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.889000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falcon-7b-instructt3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.561000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-2-13b-chat-hft1</th>\n",
       "      <td>0.985</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>0.482503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-2-13b-chat-hft1t2t3</th>\n",
       "      <td>0.736</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.872611</td>\n",
       "      <td>0.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-2-13b-chat-hft2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.425626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-2-13b-chat-hft3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.274238</td>\n",
       "      <td>0.867000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orca-13bt1</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orca-13bt1t2t3</th>\n",
       "      <td>0.720</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.562000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orca-13bt2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.876939</td>\n",
       "      <td>0.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orca-13bt3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.071918</td>\n",
       "      <td>0.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizard-15bt1</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.243697</td>\n",
       "      <td>0.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizard-15bt1t2t3</th>\n",
       "      <td>0.691</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.743287</td>\n",
       "      <td>0.584000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizard-15bt2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizard-15bt3</th>\n",
       "      <td>0.281</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.783000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Accuracy               AccuracyNoGibberish   \n",
       "Task                         task1  task2  task3               task1   \n",
       "Model                                                                  \n",
       "Falcon-7b-instructt1         0.909  0.000  0.302               0.909  \\\n",
       "Falcon-7b-instructt1t2t3     0.754  0.728  0.565               0.754   \n",
       "Falcon-7b-instructt2         0.000  0.889  0.006               0.000   \n",
       "Falcon-7b-instructt3         0.000  0.000  0.561               0.000   \n",
       "Llama-2-13b-chat-hft1        0.985  0.004  0.455               0.985   \n",
       "Llama-2-13b-chat-hft1t2t3    0.736  0.548  0.631               0.736   \n",
       "Llama-2-13b-chat-hft2        0.000  0.896  0.289               0.000   \n",
       "Llama-2-13b-chat-hft3        0.000  0.099  0.867               0.000   \n",
       "orca-13bt1                   0.699  0.000  0.495               0.699   \n",
       "orca-13bt1t2t3               0.720  0.896  0.562               0.720   \n",
       "orca-13bt2                   0.000  0.848  0.665               0.000   \n",
       "orca-13bt3                   0.000  0.021  0.901               0.000   \n",
       "wizard-15bt1                 0.017  0.232  0.499               0.017   \n",
       "wizard-15bt1t2t3             0.691  0.692  0.584               0.691   \n",
       "wizard-15bt2                 0.001  0.896  0.007               1.000   \n",
       "wizard-15bt3                 0.281  0.881  0.783               0.281   \n",
       "\n",
       "                                               \n",
       "Task                          task2     task3  \n",
       "Model                                          \n",
       "Falcon-7b-instructt1       0.000000  0.488673  \n",
       "Falcon-7b-instructt1t2t3   0.747433  0.565000  \n",
       "Falcon-7b-instructt2       0.889000  0.222222  \n",
       "Falcon-7b-instructt3       0.000000  0.561000  \n",
       "Llama-2-13b-chat-hft1      0.023392  0.482503  \n",
       "Llama-2-13b-chat-hft1t2t3  0.872611  0.631000  \n",
       "Llama-2-13b-chat-hft2      0.896000  0.425626  \n",
       "Llama-2-13b-chat-hft3      0.274238  0.867000  \n",
       "orca-13bt1                 0.000000  0.495000  \n",
       "orca-13bt1t2t3             0.896000  0.562000  \n",
       "orca-13bt2                 0.876939  0.665000  \n",
       "orca-13bt3                 0.071918  0.901000  \n",
       "wizard-15bt1               0.243697  0.499000  \n",
       "wizard-15bt1t2t3           0.743287  0.584000  \n",
       "wizard-15bt2               0.896000  0.411765  \n",
       "wizard-15bt3               0.881000  0.783000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(results, columns=['Task', 'Model', 'Accuracy', 'AccuracyNoGibberish'])\n",
    "summary_df = summary_df.pivot(index='Model', columns='Task', values=['Accuracy', 'AccuracyNoGibberish'])\n",
    "\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
