{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Parser import parse_LLM_output\n",
    "from nltk.sem.logic import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible Outputs from LM:\n",
    "nothing = \"\"\n",
    "anything = \"sdaspdjasd\"\n",
    "partially_correct = \"World model: .\"\n",
    "partially_correct_missing_info = \"World model: .\"\n",
    "another_partially_correct = \"Keys: .\"\n",
    "another_partially_correct_missing_info = \"Keys: .\"\n",
    "empty_answer = \"World model: . Keys: \"\n",
    "syntactically_correct_thing = \"World model: Rey is Zany. Louie is Zany. Keys: F: Zany. p: Rey. r: Louie..\"\n",
    "no_model_no_keys_but_correct = \"Rey is Zany. Louie is Zany. F: Zany. p: Rey. r: Louie..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_LLM_output(nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_LLM_output(anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kv: \n",
      "['World model', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_LLM_output(partially_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kv: \n",
      "['World model', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_LLM_output(partially_correct_missing_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kv: \n",
      "['Keys', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_LLM_output(another_partially_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kv: \n",
      "['Keys', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_LLM_output(another_partially_correct_missing_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". \n",
      "['']\n",
      "kv: \n",
      "['']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_LLM_output(empty_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:World model: Rey is Zany. Louie is Zany. \n",
      "1:: F: Zany. p: Rey. r: Louie..\n",
      "kv: \n",
      "['F', 'Zany']\n",
      "kv: \n",
      "['p', 'Rey']\n",
      "kv: \n",
      "['r', 'Louie']\n",
      "cm:\n",
      "[('p', 'Rey'), ('r', 'Louie')]\n",
      "Rey is Zany. Louie is Zany. \n",
      "['Rey is Zany', 'Louie is Zany', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('F', {'p'}), ('F', {'r'}), ('p', 'Rey'), ('r', 'Louie')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_LLM_output(syntactically_correct_thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kv: \n",
      "['F', 'Zany']\n",
      "kv: \n",
      "['p', 'Rey']\n",
      "kv: \n",
      "['r', 'Louie']\n",
      "cm:\n",
      "[('p', 'Rey'), ('r', 'Louie')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('F', {'p'}), ('F', {'r'}), ('p', 'Rey'), ('r', 'Louie')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_LLM_output(no_model_no_keys_but_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What else could happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['World model: ... .', ': ... .', ': ... .']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'keys', \"World model: ... .keys: ... .keys: ... .\", flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['World model: ... .']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'keys', \"World model: ... .\", flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['World model: ... .', ': ... .']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'keys', \"World model: ... .keys: ... .\", flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = re.split(r'keys', \"\", flags=re.IGNORECASE)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdas'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = \" asdas \"\n",
    "b = b.strip()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['segment', 'segment']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in '/segment/segment/'.split('/') if x] # ignores the first empty string that is usually returned with split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'Conservative']\n",
      "['q', 'Violet']\n",
      "['l', 'George']\n",
      "{'Violet': 'q', 'George': 'l'}\n",
      "{'Conservative': 'F'}\n",
      "[('q', 'Violet'), ('l', 'George')]\n"
     ]
    }
   ],
   "source": [
    "tmp = ': F: Conservative. q: Violet. l: George..'\n",
    "tmp_list = re.split('\\\\.', tmp, flags=re.IGNORECASE)\n",
    "reverse_predicate_mapping = {}\n",
    "reverse_constant_mapping = {}\n",
    "for k in tmp_list:\n",
    "    if len(k) > 0: # splitting at the last \".\" leads to an empty string\n",
    "        # clean the string (e.g. \":\" after \"keys:...\" as well as white space after \":\")\n",
    "        k = k.lstrip(\"\\\\:\")\n",
    "        kv = k.split(\":\") # split keys and values\n",
    "        kv = [i.lstrip() for i in kv] # clean whitespace\n",
    "        print(kv)\n",
    "        if kv[0].isupper(): #check for uppercase\n",
    "            reverse_predicate_mapping[kv[1]] = kv[0] # e.g. Anxious: F. instead of: F: Anxious.\n",
    "        else:\n",
    "            reverse_constant_mapping[kv[1]] = kv[0]\n",
    "print(reverse_constant_mapping)\n",
    "print(reverse_predicate_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_constant_mapping = {\"Rey\":\"a\", \"Louie\":\"b\"}\n",
    "reverse_predicate_mapping = {\"Zany\":\"Z\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rey is Zany. Louie is Zany.\n",
      "['Rey is Zany', 'Louie is Zany']\n",
      "Z\n",
      "a\n",
      "Z\n",
      "b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Z', {'a'}), ('Z', {'b'})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_expressions = []\n",
    "    \n",
    "world_model = \"World model: Rey is Zany. Louie is Zany.\"\n",
    "# clean the string\n",
    "world_model = re.sub('world model', '', world_model, flags=re.IGNORECASE)\n",
    "world_model = world_model.lstrip(\"\\\\:\")\n",
    "world_model = world_model.lstrip()\n",
    "print(world_model)\n",
    "\n",
    "world_model_list = re.split('\\\\.', world_model, flags=re.IGNORECASE)\n",
    "world_model_list = [x.strip() for x in world_model_list if x]\n",
    "print(world_model_list)\n",
    "\n",
    "for sentence in world_model_list:\n",
    "    # split sentence into words\n",
    "    sentence = sentence.split()\n",
    "    # get indices before and after is\n",
    "    # here, we require that the LLM makes well-formed sentences (i.e. subject - verb \"is\" - [not] - adj). Otherwise, we do not take it).\n",
    "    if \"is\" in sentence and sentence.index(\"is\") > 0: \n",
    "        is_index = sentence.index(\"is\")\n",
    "        if \"not\" in sentence:\n",
    "            if sentence.index(\"not\") == is_index + 1: # again: needs to be grammatically correct\n",
    "                try: # we may not have a reverse_predicate_mapping or reverse_constant_mapping, if keys are missing\n",
    "                    name = sentence[is_index - 1] \n",
    "                    adjective = sentence[is_index + 2]\n",
    "                    predicate = reverse_predicate_mapping[adjective] # mapping zum uppercase letter nötig!\n",
    "                    constant = reverse_constant_mapping[name]\n",
    "                    #nltk_expressions.append(NegatedExpression(ApplicationExpression(FunctionVariableExpression(Variable(predicate)), ConstantExpression(Variable(constant)))))\n",
    "                    nltk_expressions.append((predicate, set(constant)))\n",
    "                except:\n",
    "                    pass\n",
    "        else:\n",
    "            try: \n",
    "                name = sentence[is_index - 1] \n",
    "                adjective = sentence[is_index + 1]\n",
    "                predicate = reverse_predicate_mapping[adjective] # mapping zum uppercase letter nötig!\n",
    "                constant = reverse_constant_mapping[name]\n",
    "                #test = ApplicationExpression(FunctionVariableExpression(Variable(predicate)), ConstantExpression(Variable(constant)))\n",
    "                nltk_expressions.append((predicate, set(constant)))\n",
    "            except:\n",
    "                pass\n",
    "nltk_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rey', 'is', 'Zany']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = \"Rey is Zany\"\n",
    "ex = ex.split(\"is\")\n",
    "ex = [x.strip() for x in ex]\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rey', 'is', 'Zany']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = \"Rey is Zany\"\n",
    "ex = ex.split()\n",
    "print(ex)\n",
    "if 'is' in ex:\n",
    "    i = ex.index(\"is\")\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = 'how are you?'\n",
    "\n",
    "if len(line.split()) > 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task1': {'a': 1}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = {}\n",
    "accuracies_task1 = {}\n",
    "accuracies_task1[\"a\"] = 1\n",
    "accuracies[\"task1\"] = accuracies_task1\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test nltk parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sem.logic import Expression \n",
    "\n",
    "read_expr = Expression.fromstring\n",
    "formulas = ['exists xP(x)/asd'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "processed = []\n",
    "# find the longest substring that can be parsed by the nltk parser. Has to include a \".\" after an exists or all quantifier\n",
    "for formula in formulas:\n",
    "    l = len(formula)\n",
    "    start = formula.find('.')\n",
    "    if start == -1:\n",
    "        processed.append[\"\"]\n",
    "    else:\n",
    "        successfully_parsed = []\n",
    "        for i in range(start, l, 1):\n",
    "            try:\n",
    "                temp = read_expr(formula[0:i])\n",
    "                successfully_parsed.append(temp)\n",
    "            except:\n",
    "                pass\n",
    "        processed.append(successfully_parsed[-1])\n",
    "        \n",
    "# find the dot, do substring method after the dot! until the last (even) closing bracket that can be parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def postprocess_output(formula):\n",
    "    l = len(formula)\n",
    "    start = formula.find('.')\n",
    "    successfully_parsed = []\n",
    "    for i in range(start, l, 1):\n",
    "        try:\n",
    "            temp = read_expr(formula[0:i])\n",
    "            successfully_parsed.append(temp)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "processed2 = [postprocess_output(f) for f in formulas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "fin_list = list(map(postprocess_output, formulas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
